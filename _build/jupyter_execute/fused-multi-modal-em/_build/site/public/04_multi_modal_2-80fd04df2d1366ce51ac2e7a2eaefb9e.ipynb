{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5779fcde",
   "metadata": {},
   "source": [
    "### Guided Computation of Fused Multi-Modal Electron Microscopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f716cf1",
   "metadata": {
    "part": "Code Walkthrough"
   },
   "source": [
    "This tutorial is almost identical to the last, but now we use a new Co$_3$O$_4$-Mn$_3$O$_4$ dataset which utilizes EELS instead of EDX. We also read from a .h5 file in a similar fashion to how one would read from a .dm3, .dm4, or .emd file format. The parameters for convergence have also changed slightly, highlighting how one set of weights may not work across datasets, hence assessing cost function convergence and regularization weighting is key. Just like the previous dataset, dramatic improvement in image quality is observed within just a few minutes of parameter tuning as seen in Figure 5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118731f4",
   "metadata": {},
   "source": [
    ":::{figure} ./figs/Figure_6_Output_2.png\n",
    ":name: Raw vs Fused Co$_3$O$_4$-Mn$_3$O$_4$\n",
    ":width: 700px\n",
    "Comparison of raw input vs fused multi-modal Co$_3$O$_4$-Mn$_3$O$_4$ HAADF elastic and EDX inelastic images\n",
    ":::\n",
    "\n",
    "```{warning} Step 0: Experimental Requirements\n",
    "To reconstruct using fused multi-modal electron microscopy you need to collect both elastic (e.g. HAADF) and inelastic (e.g. EELS / EDX) maps of your material. For the elastic signal, it is important that it provides Z-contrast of your elements. For the inelastic signal, you should have all chemistries in your sample mapped. Solving for under-determined chemical maps, or using difficult to interpret elastic signals is outside the scope of this tutorial.\n",
    "```\n",
    "\n",
    "```{admonition} Step 1\n",
    "Python Imports\n",
    "```\n",
    ":::{code-cell} ipython3\n",
    "import data/fusion_utils as utils\n",
    "\n",
    "from scipy.sparse import spdiags\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "import h5py\n",
    ":::\n",
    "\n",
    "```{admonition} Step 2\n",
    "For this example, the dataset is stored in a .h5 file so this is how you can extract data and then save it numpy arrays for the fused multi-modal workflow.\n",
    "```\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "data = 'data/Co3O4_Mn3O4_dataset.h5'\n",
    "\n",
    "# Define element names and their atomic weights\n",
    "elem_names=['Co', 'Mn', 'O']\n",
    "elem_weights=[27,25,8]\n",
    "# Parse elastic HAADF data and inelastic chemical maps based on element index from line above\n",
    "with h5py.File(data, 'r') as h5_file:\n",
    "    HAADF = np.array(h5_file['HAADF'])\n",
    "xx = np.array([],dtype=np.float32)\n",
    "for ee in elem_names:\n",
    "\t# Read chemical maps\n",
    "    with h5py.File(data, 'r') as h5_file:\n",
    "        chemMap = np.array(h5_file[ee])\n",
    "        \n",
    "  # Check if chemMap has the same dimensions as HAADF\n",
    "\tif chemMap.shape != HAADF.shape:\n",
    "\t\traise ValueError(f\"The dimensions of {ee} chemical map do not match HAADF dimensions.\")\n",
    "\t\n",
    "\n",
    "\t# Set Noise Floor to Zero and Normalize Chemical Maps\n",
    "\tchemMap -= np.min(chemMap); chemMap /= np.max(chemMap)\n",
    "\n",
    "\t# Concatenate Chemical Map to Variable of Interest\n",
    "\txx = np.concatenate([xx,chemMap.flatten()])\n",
    ":::\n",
    "\n",
    "```{admonition} Step 3\n",
    "Reshape your data\n",
    "```\n",
    "\n",
    "```{danger} Caution!\n",
    "Do not change the code below.\n",
    "```\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "# Make Copy of Raw Measurements for Poisson Maximum Likelihood Term \n",
    "xx0 = xx.copy()\n",
    "\n",
    "# Incoherent linear imaging for elastic scattering scales with atomic number Z raised to γ  ∈ [1.4, 2]\n",
    "gamma = 1.6 \n",
    "\n",
    "# Image Dimensions\n",
    "(nx, ny) = chemMap.shape; nPix = nx * ny\n",
    "nz = len(elem_names)\n",
    "\n",
    "# C++ TV Min Regularizers\n",
    "reg = utils.tvlib(nx,ny)\n",
    "\n",
    "# Data Subtraction and Normalization \n",
    "HAADF -= np.min(HAADF); HAADF /= np.max(HAADF)\n",
    "HAADF=HAADF.flatten()\n",
    "\n",
    "# Create Summation Matrix\n",
    "A = utils.create_weighted_measurement_matrix(nx,ny,nz,elem_weights,gamma,1)\n",
    ":::\n",
    "\n",
    "```{admonition} Optional\n",
    ":class: tip \n",
    "Plot your raw elastic/inelastic data\n",
    "```\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "fig, ax = plt.subplots(1, nz + 1, figsize=(15, 8))  # Updated to accommodate an additional subplot for HAADF\n",
    "ax = ax.flatten()\n",
    "\n",
    "for ii in range(nz):\n",
    "    ax[ii].imshow(xx0[ii*(nx*ny):(ii+1)*(nx*ny)].reshape(nx, ny), cmap='gray', vmax=0.3)\n",
    "    ax[ii].set_title(elem_names[ii])\n",
    "    ax[ii].axis('off')\n",
    "\n",
    "ax[nz].imshow(HAADF.reshape(nx, ny), cmap='gray')\n",
    "ax[nz].set_title('HAADF')\n",
    "ax[nz].axis('off')\n",
    "\n",
    "plt.show()\n",
    ":::\n",
    "\n",
    "```{admonition} Step 4\n",
    "Fine tune your weights for each of the three parts of the cost function.\n",
    "```\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "# Convergence Parameters\n",
    "lambdaHAADF = 1/nz # Do not modify this\n",
    "lambdaChem = 1e-3\n",
    "nIter = 30 # Typically 10-15 will suffice\n",
    "lambdaTV = 0.006; #Typically between 0.001 and 1\n",
    "bkg = 1e-8\n",
    "\n",
    "# FGP TV Parameters\n",
    "regularize = True; nIter_TV = 5; \n",
    ":::\n",
    "\n",
    "```{admonition} Step 5\n",
    "Run the Fused Multi-Modal algorithm. Here an extra line was added to subtract off some of the constant background noise.  This can be helpful when inelastic maps are exceptionally noisy.  The ideal value to background subtract off was found by looking at the mean value of the image found in regions of the image where clear material structure was not present\n",
    "```\n",
    "\n",
    "```{danger} Caution!\n",
    "Do not change the code below.\n",
    "```\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "# xx represents the flattened 1D elastic maps we are trying to improve via the cost function\n",
    "xx = xx0.copy()\n",
    "\n",
    "# Background noise subtraction for improved convergence\n",
    "xx = np.where((xx < .2), 0, xx)\n",
    "\n",
    "# Auxiliary Functions for measuring the cost functions\n",
    "lsqFun = lambda inData : 0.5 * np.linalg.norm(A.dot(inData**gamma) - HAADF) **2\n",
    "poissonFun = lambda inData : np.sum(xx0 * np.log(inData + 1e-8) - inData)\n",
    "\n",
    "# Main Loop\n",
    "\n",
    "# Initialize the three cost functions components \n",
    "costHAADF = np.zeros(nIter,dtype=np.float32); costChem = np.zeros(nIter, dtype=np.float32); costTV = np.zeros(nIter, dtype=np.float32);\n",
    "\n",
    "for kk in tqdm(range(nIter)):\n",
    "\t# Solve for the first two optimization functions $\\Psi_1$ and $\\Psi_2$\n",
    "\txx -=  gamma * spdiags(xx**(gamma - 1), [0], nz*nx*ny, nz*nx*ny) * lambdaHAADF * A.transpose() * (A.dot(xx**gamma) - HAADF) + lambdaChem * (1 - xx0 / (xx + bkg))\n",
    "\n",
    "\t# Enforce positivity constraint\n",
    "\txx[xx<0] = 0\n",
    "\n",
    "\t# FGP Regularization if turned on\n",
    "\tif regularize:\n",
    "\t\tfor zz in range(nz):\n",
    "\t\t\txx[zz*nPix:(zz+1)*nPix] = reg.fgp_tv( xx[zz*nPix:(zz+1)*nPix].reshape(nx,ny), lambdaTV, nIter_TV).flatten()\n",
    "\n",
    "\t\t\t# Measure TV Cost Function\n",
    "\t\t\tcostTV[kk] += reg.tv( xx[zz*nPix:(zz+1)*nPix].reshape(nx,ny) )\n",
    "\t\t\t\n",
    "\t# Measure $\\Psi_1$ and $\\Psi_2$ Cost Functions\n",
    "\tcostHAADF[kk] = lsqFun(xx); costChem[kk] = poissonFun(xx)\n",
    ":::\n",
    "\n",
    "```{admonition} Step 6\n",
    "Assess convergence by confirming that all 3 cost functions asymptotically approach a low value.\n",
    "```\n",
    "\n",
    "```{admonition} Be careful with $\\lambda_{TV}$!\n",
    ":class: attention\n",
    "```\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "# Display Cost Functions and Descent Parameters\n",
    "utils.plot_convergence(costHAADF, lambdaHAADF, costChem, lambdaChem, costTV, lambdaTV)\n",
    "# Show Reconstructed Signal\n",
    "fig, ax = plt.subplots(2, len(elem_names), figsize=(12, 8))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for ii in range(len(elem_names)):\n",
    "    ax[ii].imshow(xx[ii*(nx*ny):(ii+1)*(nx*ny)].reshape(nx, ny), cmap='gray')\n",
    "    ax[ii].set_title(elem_names[ii])\n",
    "    ax[ii].axis('off')\n",
    "    \n",
    "    ax[ii + len(elem_names)].imshow(xx[ii*(nx*ny):(ii+1)*(nx*ny)].reshape(nx, ny)[40:100, 50:110], cmap='gray')\n",
    "    ax[ii + len(elem_names)].set_title(elem_names[ii] + ' Cropped')\n",
    "    ax[ii + len(elem_names)].axis('off')\n",
    "\n",
    "plt.show()\n",
    ":::\n",
    "\n",
    "```{admonition} Step 7\n",
    "Save your data\n",
    "```\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "save_folder_name='test'\n",
    "utils.save_data(save_folder_name, xx0, xx, HAADF, A.dot(xx**gamma), elem_names, nx, ny, costHAADF, costChem, costTV, lambdaHAADF, lambdaChem, lambdaTV, gamma)\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "numbering": {
   "enumerator": "5.%s"
  },
  "source_map": [
   14,
   17,
   19
  ],
  "title": "Multi-Modal Tutorial Dataset 2"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}