{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Multi-Modal Tutorial Dataset 1\n",
    "numbering:\n",
    "  enumerator: 4.%s\n",
    "jupytext:\n",
    "  formats: md:myst\n",
    "  text_representation:\n",
    "    extension: .md\n",
    "    format_name: myst\n",
    "kernelspec:\n",
    "  display_name: Python 3\n",
    "  language: python\n",
    "  name: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided Computation of Fused Multi-Modal Electron Microscopy\n",
    "\n",
    "+++ {\"part\": \"Code Walkthrough\"} \n",
    "In this tutorial we walkthough how you can fuse your EELS/EDX maps with HAADF or similar elastic imaging modalities to improve chemical resolution. This is Tutorial 1 of 2 where we look at an atomic resolution HAADF and EDX dataset of DyScO$_3$. The multi-modal data fusion workflow relies on Python, and requires minimal user input with <10 tunable lines. Both here and in the Mathematical Overview section we outline best practices for these adjustments.  Within a few minutes, datasets such as the one in this tutorial can be transformed into resolution enhanced chemical maps. (Figure 4.1)\n",
    "+++\n",
    "\n",
    ":::{figure} ./figs/Figure_3_Output.png\n",
    ":name: Raw vs Fused DyScO$_3$\n",
    ":width: 700px\n",
    "Comparison of raw input vs fused multi-modal DyScO$_3$ HAADF elastic and EDX inelastic images\n",
    ":::\n",
    "```{warning} Step 0: Experimental Requirements\n",
    "To reconstruct using fused multi-modal electron microscopy you need to collect both elastic (e.g. HAADF) and inelastic (e.g. EELS / EDX) maps of your material. For the elastic signal, it is important that it provides Z-contrast of your elements. For the inelastic signal, you should have all chemistries in your sample mapped. Solving for under-determined chemical maps, or using difficult to interpret elastic signals are outside the scope of this tutorial. The collected chemical maps and HAADF must all have the same dimensionality, i.e. the same image size and number of pixels.  For this reason, we recommend using the HAADF signal that is simultaneously collected when taking an EDX/EELS scan\n",
    "```\n",
    "\n",
    "```{admonition} Step 1: Python Imports\n",
    "First, we import standard python packages alongside our custom class of functions for data fusion called [fusion_utils](https://github.com/jtschwar/Multi-Modal-2D-Data-Fusion/blob/170fea3292da7e6390bfff7236610eb0c8077ff7/EDX/fusion_utils.py). The fusion_utils package contains 3 functions and a class of TV functions: save_data(), plot_convergence(), create_weighted_measurement_matrix(), and tvlib(). The save_data function saves the fused images into .tif files and all the parameters and matrix data into a .h5 file. Plot_convergence plots the convergence of the cost functions. Create_weighted_measurement_matrix is for generating the first part of our cost function that relates the elastic and inelastic modalities. Finally, the class of functions called tvlib performs the Fast Gradient Project (FGP) method of TV image denoising, which deblurs output images while preserving edges.\n",
    "```\n",
    "import data/fusion_utils as utils\n",
    "\n",
    "from scipy.sparse import spdiags\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
