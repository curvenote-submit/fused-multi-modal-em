{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: app:step1\n",
    "\n",
    "import ../data/fusion_utils as utils\n",
    "\n",
    "from scipy.sparse import spdiags\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: app:step2\n",
    "\n",
    "data = np.load('data/PTO_Trilayer_dataset.npz')\n",
    "# Define element names and their atomic weights\n",
    "elem_names=['Sc', 'Dy', 'O']\n",
    "elem_weights=[21,66,8]\n",
    "# Parse elastic HAADF data and inelastic chemical maps based on element index from line above\n",
    "HAADF = data['HAADF']\n",
    "xx = np.array([],dtype=np.float32)\n",
    "for ee in elem_names:\n",
    "\n",
    "\t# Read Chemical Map for Element \"ee\"\n",
    "\tchemMap = data[ee]\n",
    "\n",
    "    # Check if chemMap has the same dimensions as HAADF\n",
    "\tif chemMap.shape != HAADF.shape:\n",
    "\t\traise ValueError(f\"The dimensions of {ee} chemical map do not match HAADF dimensions.\")\n",
    "\t\n",
    "\t# Set Noise Floor to Zero and Normalize Chemical Maps\n",
    "\tchemMap -= np.min(chemMap); chemMap /= np.max(chemMap)\n",
    "\n",
    "\t# Concatenate Chemical Map to Variable of Interest\n",
    "\txx = np.concatenate([xx,chemMap.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: app:step31\n",
    "\n",
    "\n",
    "# Make Copy of Raw Measurements for Poisson Maximum Likelihood Term \n",
    "xx0 = xx.copy()\n",
    "\n",
    "# Incoherent linear imaging for elastic scattering scales with atomic number Z raised to γ  ∈ [1.4, 2]\n",
    "gamma = 1.6 \n",
    "\n",
    "# Image Dimensions\n",
    "(nx, ny) = chemMap.shape; nPix = nx * ny\n",
    "nz = len(elem_names)\n",
    "\n",
    "# C++ TV Min Regularizers\n",
    "reg = utils.tvlib(nx,ny)\n",
    "\n",
    "# Data Subtraction and Normalization \n",
    "HAADF -= np.min(HAADF); HAADF /= np.max(HAADF)\n",
    "HAADF=HAADF.flatten()\n",
    "\n",
    "# Create Summation Matrix\n",
    "A = utils.create_weighted_measurement_matrix(nx,ny,nz,elem_weights,gamma,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: app:step32\n",
    "\n",
    "fig, ax = plt.subplots(2,len(elem_names)+1,figsize=(12,8))\n",
    "ax = ax.flatten()\n",
    "ax[0].imshow(HAADF.reshape(nx,ny),cmap='gray'); ax[0].set_title('HAADF'); ax[0].axis('off')\n",
    "ax[1+len(elem_names)].imshow(HAADF.reshape(nx,ny)[70:130,25:85],cmap='gray'); ax[1+len(elem_names)].set_title('HAADF Cropped'); ax[1+len(elem_names)].axis('off')\n",
    "\n",
    "for ii in range(len(elem_names)):\n",
    "    ax[ii+1].imshow(xx0[ii*(nx*ny):(ii+1)*(nx*ny)].reshape(nx,ny),cmap='gray'); ax[ii+1].set_title(elem_names[ii]); ax[ii+1].axis('off')\n",
    "    ax[ii+2+len(elem_names)].imshow(xx0[ii*(nx*ny):(ii+1)*(nx*ny)].reshape(nx,ny)[70:130,25:85],cmap='gray'); ax[ii+2+len(elem_names)].set_title(elem_names[ii]+' Cropped'); ax[ii+2+len(elem_names)].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: app:step4\n",
    "\n",
    "# Convergence Parameters\n",
    "lambdaHAADF = 1/nz # Do not modify this\n",
    "lambdaChem = 0.08\n",
    "lambdaTV = 0.15; #Typically between 0.001 and 1\n",
    "nIter = 30 # Typically 10-15 will suffice\n",
    "bkg = 2.4e-1\n",
    "\n",
    "# FGP TV Parameters\n",
    "regularize = True; nIter_TV = 3; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: app:step5\n",
    "\n",
    "# xx represents the flattened 1D elastic maps we are trying to improve via the cost function\n",
    "xx = xx0.copy()\n",
    "\n",
    "# Auxiliary Functions for measuring the cost functions\n",
    "lsqFun = lambda inData : 0.5 * np.linalg.norm(A.dot(inData**gamma) - HAADF) **2\n",
    "poissonFun = lambda inData : np.sum(xx0 * np.log(inData + 1e-8) - inData)\n",
    "\n",
    "# Main Loop\n",
    "\n",
    "# Initialize the three cost functions components \n",
    "costHAADF = np.zeros(nIter,dtype=np.float32); costChem = np.zeros(nIter, dtype=np.float32); costTV = np.zeros(nIter, dtype=np.float32);\n",
    "\n",
    "for kk in tqdm(range(nIter)):\n",
    "\t# Solve for the first two optimization functions $\\Psi_1$ and $\\Psi_2$\n",
    "\txx -=  gamma * spdiags(xx**(gamma - 1), [0], nz*nx*ny, nz*nx*ny) * lambdaHAADF * A.transpose() * (A.dot(xx**gamma) - HAADF) + lambdaChem * (1 - xx0 / (xx + bkg))\n",
    "\n",
    "\t# Enforce positivity constraint\n",
    "\txx[xx<0] = 0\n",
    "\n",
    "\t# FGP Regularization if turned on\n",
    "\tif regularize:\n",
    "\t\tfor zz in range(nz):\n",
    "\t\t\txx[zz*nPix:(zz+1)*nPix] = reg.fgp_tv( xx[zz*nPix:(zz+1)*nPix].reshape(nx,ny), lambdaTV, nIter_TV).flatten()\n",
    "\n",
    "\t\t\t# Measure TV Cost Function\n",
    "\t\t\tcostTV[kk] += reg.tv( xx[zz*nPix:(zz+1)*nPix].reshape(nx,ny) )\n",
    "\t\t\t\n",
    "\t# Measure $\\Psi_1$ and $\\Psi_2$ Cost Functions\n",
    "\tcostHAADF[kk] = lsqFun(xx); costChem[kk] = poissonFun(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: app:step6\n",
    "\n",
    "# Display Cost Functions and Descent Parameters\n",
    "utils.plot_convergence(costHAADF, lambdaHAADF, costChem, lambdaChem, costTV, lambdaTV)\n",
    "# Show Reconstructed Signal\n",
    "fig, ax = plt.subplots(2,len(elem_names)+1,figsize=(12,8))\n",
    "ax = ax.flatten()\n",
    "ax[0].imshow((A.dot(xx**gamma)).reshape(nx,ny),cmap='gray'); ax[0].set_title('HAADF'); ax[0].axis('off')\n",
    "ax[1+len(elem_names)].imshow((A.dot(xx**gamma)).reshape(nx,ny)[70:130,25:85],cmap='gray'); ax[1+len(elem_names)].set_title('HAADF Cropped'); ax[1+len(elem_names)].axis('off')\n",
    "\n",
    "for ii in range(len(elem_names)):\n",
    "    ax[ii+1].imshow(xx[ii*(nx*ny):(ii+1)*(nx*ny)].reshape(nx,ny),cmap='gray'); ax[ii+1].set_title(elem_names[ii]); ax[ii+1].axis('off')\n",
    "    ax[ii+2+len(elem_names)].imshow(xx[ii*(nx*ny):(ii+1)*(nx*ny)].reshape(nx,ny)[70:130,25:85],cmap='gray'); ax[ii+2+len(elem_names)].set_title(elem_names[ii]+' Cropped'); ax[ii+2+len(elem_names)].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: app:step7\n",
    "\n",
    "save_folder_name='test'\n",
    "utils.save_data(save_folder_name, xx0, xx, HAADF, A.dot(xx**gamma), elem_names, nx, ny, costHAADF, costChem, costTV, lambdaHAADF, lambdaChem, lambdaTV, gamma)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
